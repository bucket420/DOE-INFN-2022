{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ee9cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import uproot\n",
    "\n",
    "def get_total_size(path, n_files):\n",
    "    filenames = sorted(os.listdir(path))\n",
    "    total_size = sum([os.path.getsize(path + filenames[i]) for i in range(n_files)])\n",
    "    return total_size / (2**30)\n",
    "\n",
    "def col_average(data):\n",
    "    n_rows = len(data)\n",
    "    n_cols = len(data[0])\n",
    "    return [sum([data[i][j] for i in range(1, n_rows)]) / (n_rows - 1) for j in range(n_cols)]\n",
    "\n",
    "def col_standard_deviation(data):\n",
    "    n_rows = len(data)\n",
    "    n_cols = len(data[0])\n",
    "    mean = col_average(data)\n",
    "    return [(sum([(data[i][j] - mean[j])**2 for i in range(1, n_rows)]) / (n_rows - 1))**0.5 for j in range(n_cols)]\n",
    "\n",
    "    \n",
    "def partition_helper(slice_entries, file_entries, file_curr, entry_curr):\n",
    "    if slice_entries <= file_entries[file_curr] - entry_curr:\n",
    "        return [file_curr, slice_entries + entry_curr]\n",
    "    elif file_curr == len(file_entries) - 1:\n",
    "        return [file_curr, file_entries[-1]]\n",
    "    else:\n",
    "        return partition_helper(slice_entries - file_entries[file_curr] + entry_curr, file_entries, file_curr + 1, 0)\n",
    "\n",
    "def partition(files, n_processes):\n",
    "    file_entries = [file.num_entries for file in files]\n",
    "    slice_entries = math.ceil(sum(file_entries) / n_processes)\n",
    "    slices = []\n",
    "    file_start = 0\n",
    "    entry_start = 0\n",
    "    for i in range(n_processes):\n",
    "        slices.append([file_start, entry_start] + partition_helper(slice_entries, file_entries, file_start, entry_start))\n",
    "        file_start = slices[-1][-2]\n",
    "        entry_start = slices[-1][-1]\n",
    "    return slices\n",
    "\n",
    "def read_slice(files, slices, index, data):\n",
    "    data_slice = []\n",
    "    for i in range(slices[index][0], slices[index][2] + 1):\n",
    "        data_slice.append(files[i].arrays(\"candidate_vMass\", \n",
    "                              \"(candidate_charge == 0)\\\n",
    "                              & (candidate_cosAlpha > 0.99)\\\n",
    "                              & (candidate_lxy / candidate_lxyErr > 3.0)\\\n",
    "                              & (candidate_vProb > 0.05)\\\n",
    "                              & (ditrack_mass > 1.014) & (ditrack_mass < 1.024)\\\n",
    "                              & (candidate_vMass > 5.33) & (candidate_vMass < 5.4)\",\n",
    "                              entry_start=slices[index][1] if i == slices[index][0] else None,\n",
    "                              entry_stop=slices[index][3] if i == slices[index][2] else None,\n",
    "                              array_cache=None,\n",
    "                              library=\"np\")[\"candidate_vMass\"])\n",
    "    data.append(np.concatenate(tuple(data_slice)))\n",
    "\n",
    "def runtime_measure_mp(path, n_files, n_processes):\n",
    "    if n_files == 0: return 0\n",
    "    if n_processes == 0: return runtime_measure(path, n_files)\n",
    "    start = time.time()\n",
    "    files = [uproot.open(path=path + filename + \":rootuple/CandidateTree\", object_cache=None, array_cache=None) for filename in sorted(os.listdir(path))[:n_files]]\n",
    "    slices = partition(files, n_processes)\n",
    "    data = multiprocessing.Manager().list()\n",
    "    processes = []\n",
    "    for i in range(n_processes):\n",
    "        p = multiprocessing.Process(target=read_slice, args=[files, slices, i, data])\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    np.concatenate(tuple(data))\n",
    "    \n",
    "    return time.time() - start\n",
    "\n",
    "def runtime_measure(path, n_files):\n",
    "    if n_files == 0: return 0\n",
    "    start = time.time()\n",
    "    files = [uproot.open(path=path + filename + \":rootuple/CandidateTree\", object_cache=None, array_cache=None) for filename in sorted(os.listdir(path))[:n_files]]\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(file.arrays(\"candidate_vMass\", \n",
    "                              \"(candidate_charge == 0)\\\n",
    "                              & (candidate_cosAlpha > 0.99)\\\n",
    "                              & (candidate_lxy / candidate_lxyErr > 3.0)\\\n",
    "                              & (candidate_vProb > 0.05)\\\n",
    "                              & (ditrack_mass > 1.014) & (ditrack_mass < 1.024)\\\n",
    "                              & (candidate_vMass > 5.33) & (candidate_vMass < 5.4)\",\n",
    "                              array_cache=None,\n",
    "                              library=\"np\")[\"candidate_vMass\"])\n",
    "        \n",
    "    np.concatenate(tuple(data))\n",
    "    \n",
    "    return time.time() - start\n",
    "\n",
    "def runtime_vs_variable(path, target_dir, measure_function, variable, step, n_loops, var_max, constant=None):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    result_path = (\"%s/runtime_vs_%s_%d_%d_%d_%d.csv\" % (target_dir, variable, constant, var_max, step, n_loops)) if constant else (\"%s/runtime_vs_%s_%d_%d_%d.csv\" % (target_dir, variable, var_max, step, n_loops))\n",
    "    \n",
    "    x = [get_total_size(path, a) for a in range(0, var_max + step, step)] if \"size\" in variable else [a for a in range(0, var_max + step, step)]\n",
    "        \n",
    "    with open(result_path, \"w+\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow(x)\n",
    "    for n in range(n_loops):\n",
    "        y = [measure_function(*(path, i if \"size\" in variable else constant, constant if \"size\" in variable else i) if constant else (path, i)) for i in range(0, var_max + step, step)]\n",
    "        with open(result_path, \"a+\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(y)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7aaca91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/128_files/\"\n",
    "target_dir = \"runtime_tests_uproot/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d24882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_vs_variable(path, target_dir, runtime_measure, \"size\", 1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fa843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d3dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73a036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
